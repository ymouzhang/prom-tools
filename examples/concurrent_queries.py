#!/usr/bin/env python3
"""
Prometheus å¹¶å‘æŸ¥è¯¢ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¼˜åŒ–åçš„ PrometheusClient è¿›è¡Œé«˜æ•ˆçš„å¹¶å‘æŸ¥è¯¢
"""

import asyncio
import time
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from prom_tools import PrometheusClient, Query, QueryResult


def setup_logger():
    """è®¾ç½®æ—¥å¿—æ ¼å¼"""
    formatter = logging.Formatter(
        fmt='%(asctime)s | %(levelname)-8s | %(filename)s:%(lineno)d | %(funcName)s() | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)

    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    logger.addHandler(console_handler)

    return logger


logger = setup_logger()


class QueryDemo:
    def __init__(self):
        self.client = PrometheusClient(url="http://localhost:9090")

    def create_monitoring_queries(self) -> list[Query]:
        """åˆ›å»ºç›‘æ§æŸ¥è¯¢åˆ—è¡¨"""
        return [
            # åŸºç¡€æœåŠ¡ç›‘æ§
        Query(name="æœåŠ¡å¯ç”¨æ€§", query="up", description="æ£€æŸ¥æ‰€æœ‰æœåŠ¡çš„åœ¨çº¿çŠ¶æ€"),
        Query(name="Prometheusç‰ˆæœ¬", query="prometheus_build_info", description="Prometheusç‰ˆæœ¬ä¿¡æ¯"),

        # ç³»ç»Ÿæ€§èƒ½ç›‘æ§
        Query(name="CPUä½¿ç”¨ç‡", query="rate(process_cpu_seconds_total[5m]) * 100", description="CPUä½¿ç”¨ç‡ç™¾åˆ†æ¯”"),
        Query(name="å†…å­˜ä½¿ç”¨é‡", query="process_resident_memory_bytes / 1024 / 1024", description="å†…å­˜ä½¿ç”¨é‡(MB)"),
        Query(name="æ–‡ä»¶æè¿°ç¬¦", query="process_open_fds", description="æ‰“å¼€çš„æ–‡ä»¶æè¿°ç¬¦æ•°é‡"),

        # HTTP è¯·æ±‚ç›‘æ§
        Query(name="HTTPè¯·æ±‚æ€»æ•°", query="prometheus_http_requests_total", description="HTTPè¯·æ±‚æ€»æ•°"),
        Query(name="HTTPè¯·æ±‚é€Ÿç‡", query="sum(rate(prometheus_http_requests_total[5m]))", description="HTTPè¯·æ±‚é€Ÿç‡"),
        Query(name="è¯·æ±‚å¤„ç†å»¶è¿Ÿ", query="histogram_quantile(0.95, rate(prometheus_http_request_duration_seconds_bucket[5m]))", description="95åˆ†ä½å»¶è¿Ÿ"),

        # å­˜å‚¨ç›‘æ§
        Query(name="æ—¶é—´åºåˆ—æ•°é‡", query="prometheus_tsdb_head_series", description="å½“å‰æ—¶é—´åºåˆ—æ€»æ•°"),
        Query(name="å†…å­˜æ ·æœ¬", query="prometheus_tsdb_head_samples_appended_total", description="å†…å­˜æ ·æœ¬æ€»æ•°"),
        Query(name="æ•°æ®å—æ•°é‡", query="prometheus_tsdb_head_chunks", description="æ•°æ®å—æ€»æ•°"),

        # ç½‘ç»œç›‘æ§
        Query(name="ç½‘ç»œè¿æ¥æ•°", query="process_net_connections", description="ç½‘ç»œè¿æ¥æ•°"),
        Query(name="ç½‘ç»œå­—èŠ‚ä¼ è¾“", query="rate(process_net_bytes_total[5m])", description="ç½‘ç»œå­—èŠ‚ä¼ è¾“é€Ÿç‡"),

        # èšåˆåˆ†ææŸ¥è¯¢
        Query(name="Top5 CPUä½¿ç”¨", query="topk(5, rate(process_cpu_seconds_total[5m]) * 100)", description="CPUä½¿ç”¨ç‡æœ€é«˜çš„5ä¸ªå®ä¾‹"),
        Query(name="æ€»è¯·æ±‚æ•°è¶‹åŠ¿", query="increase(prometheus_http_requests_total[1h])", description="1å°æ—¶è¯·æ±‚å¢é‡"),
    ]
    
    def create_range_queries(self, start_time: datetime, end_time: datetime) -> list[Query]:
        """åˆ›å»ºèŒƒå›´æŸ¥è¯¢åˆ—è¡¨"""
        range_queries = [
            Query(
                name="2å°æ—¶CPUè¶‹åŠ¿",
                query="rate(process_cpu_seconds_total[5m]) * 100",
                start=start_time,
                end=end_time,
                step="5m"
            ),
            Query(
                name="2å°æ—¶å†…å­˜è¶‹åŠ¿",
                query="process_resident_memory_bytes / 1024 / 1024",
                start=start_time,
                end=end_time,
                step="10m"
            ),
            Query(
                name="2å°æ—¶è¯·æ±‚é€Ÿç‡",
                query="sum(rate(prometheus_http_requests_total[5m]))",
                start=start_time,
                end=end_time,
                step="5m"
            ),
            Query(
                query="up"
            ),
        ]
        return range_queries

    def display_query_result(self, result: QueryResult):
        """å±•ç¤ºæŸ¥è¯¢ç»“æœ"""
        if result.success:
            logger.info(f"âœ… {result.display_name}")
            logger.info(f"    æŸ¥è¯¢è¯­å¥: {result.query}")
            logger.info(f"    æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f}s")
            logger.info(f"    æŒ‡æ ‡æ•°é‡: {result.metric_count}")
            logger.info(f"    æŒ‡æ ‡è¯¦æƒ…:")
            metrics_summary = result.get_metrics_summary(limit=3)
            for metric in metrics_summary:
                if metric['value'] is not None:
                    logger.info(f"      ğŸ“Š {metric['name']}: {metric['value']:.2f}")
                    if metric['labels']:
                        logger.info(f"         æ ‡ç­¾: {metric['labels']}")
                else:
                    logger.info(f"      ğŸ“Š {metric['name']}: æ— æ•°æ®")
            else:
                logger.info("    âš ï¸  æ— æŒ‡æ ‡æ•°æ®")
        else:
            logger.error(f"âŒ {result.display_name}")
            logger.error(f"    æŸ¥è¯¢è¯­å¥: {result.query}")
            logger.error(f"    é”™è¯¯ä¿¡æ¯: {result.error}")
            logger.error(f"    æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f}s")
        logger.info("")  # ç©ºè¡Œåˆ†éš”


    async def concurrent_queries_example(self):
        """å¹¶å‘æŸ¥è¯¢ç¤ºä¾‹"""
        logger.info("ğŸš€ Prometheus å¹¶å‘æŸ¥è¯¢ç¤ºä¾‹")
        logger.info("=" * 60)
    
        try:
            # åˆ›å»ºæŸ¥è¯¢åˆ—è¡¨
            queries = self.create_monitoring_queries()
            logger.info(f"å‡†å¤‡æ‰§è¡Œ {len(queries)} ä¸ªå¹¶å‘æŸ¥è¯¢:")
    
            for i, query in enumerate(queries, 1):
                logger.info(f"  [{i}] {query}")
    
            logger.info("\n" + "=" * 60)
            logger.info("å¼€å§‹å¹¶å‘æ‰§è¡ŒæŸ¥è¯¢...")
    
            # æ‰§è¡Œå¹¶å‘æŸ¥è¯¢
            start_time = time.time()
            results = await self.client.query_multiple(queries, max_concurrent=8)
            total_time = time.time() - start_time
    
            logger.info(f"å¹¶å‘æŸ¥è¯¢å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}s\n")
    
            # ç»Ÿè®¡ç»“æœ
            successful_results = [r for r in results if r.success]
            failed_results = [r for r in results if not r.success]
    
            logger.info("ğŸ“Š æŸ¥è¯¢ç»“æœç»Ÿè®¡:")
            logger.info(f"  æ€»æŸ¥è¯¢æ•°: {len(results)}")
            logger.info(f"  æˆåŠŸæŸ¥è¯¢: {len(successful_results)}")
            logger.info(f"  å¤±è´¥æŸ¥è¯¢: {len(failed_results)}")
            logger.info(f"  æˆåŠŸç‡: {len(successful_results)/len(results)*100:.1f}%")
    
            # æ€§èƒ½ç»Ÿè®¡
            if successful_results:
                execution_times = [r.execution_time for r in successful_results if r.execution_time]
                if execution_times:
                    avg_time = sum(execution_times) / len(execution_times)
                    max_time = max(execution_times)
                    min_time = min(execution_times)
                    logger.info(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
                    logger.info(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.3f}s")
                    logger.info(f"  æœ€é•¿æ‰§è¡Œæ—¶é—´: {max_time:.3f}s")
                    logger.info(f"  æœ€çŸ­æ‰§è¡Œæ—¶é—´: {min_time:.3f}s")
    
            logger.info("\n" + "=" * 60)
            logger.info("è¯¦ç»†æŸ¥è¯¢ç»“æœ:")
            logger.info("=" * 60)
    
            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
            for result in results:
                self.display_query_result(result)
    
            # æŒ‡æ ‡æ±‡æ€»ç»Ÿè®¡
            logger.info("ğŸ“ˆ æŒ‡æ ‡æ±‡æ€»ç»Ÿè®¡:")
            total_metrics = sum(r.metric_count for r in successful_results)
            logger.info(f"  æ€»æŒ‡æ ‡æ•°: {total_metrics}")
    
            if successful_results:
                # æŒ‰æŸ¥è¯¢ç±»å‹åˆ†ç±»ç»Ÿè®¡
                basic_queries = [r for r in successful_results if any(x in r.query.lower() for x in ['up', 'build_info'])]
                performance_queries = [r for r in successful_results if any(x in r.query.lower() for x in ['cpu', 'memory', 'fds'])]
                http_queries = [r for r in successful_results if any(x in r.query.lower() for x in ['http'])]
                storage_queries = [r for r in successful_results if any(x in r.query.lower() for x in ['tsdb'])]
                network_queries = [r for r in successful_results if any(x in r.query.lower() for x in ['net'])]
                aggregate_queries = [r for r in successful_results if any(x in r.query.lower() for x in ['topk', 'increase'])]
    
                logger.info(f"  åŸºç¡€ç›‘æ§: {len(basic_queries)} ä¸ªæŸ¥è¯¢")
                logger.info(f"  æ€§èƒ½ç›‘æ§: {len(performance_queries)} ä¸ªæŸ¥è¯¢")
                logger.info(f"  HTTPç›‘æ§: {len(http_queries)} ä¸ªæŸ¥è¯¢")
                logger.info(f"  å­˜å‚¨ç›‘æ§: {len(storage_queries)} ä¸ªæŸ¥è¯¢")
                logger.info(f"  ç½‘ç»œç›‘æ§: {len(network_queries)} ä¸ªæŸ¥è¯¢")
                logger.info(f"  èšåˆåˆ†æ: {len(aggregate_queries)} ä¸ªæŸ¥è¯¢")
    
        except Exception as e:
            logger.error(f"å¹¶å‘æŸ¥è¯¢ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        finally:
            await self.client.close()
            logger.info("ğŸ”š å…³é—­å®¢æˆ·ç«¯è¿æ¥")


    async def range_queries_example(self):
        """èŒƒå›´æŸ¥è¯¢ç¤ºä¾‹"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š èŒƒå›´æŸ¥è¯¢ç¤ºä¾‹")
        logger.info("=" * 60)

        try:
            # è®¾ç½®æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=2)

            # åˆ›å»ºèŒƒå›´æŸ¥è¯¢
            range_queries = self.create_range_queries(start_time, end_time)
            logger.info(f"æ‰§è¡Œ {len(range_queries)} ä¸ªèŒƒå›´æŸ¥è¯¢")

            # æ‰§è¡ŒèŒƒå›´æŸ¥è¯¢
            start_time = time.time()
            results = await self.client.query_multiple(range_queries, max_concurrent=3)
            total_time = time.time() - start_time

            logger.info(f"èŒƒå›´æŸ¥è¯¢å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}s\n")

            # æ˜¾ç¤ºèŒƒå›´æŸ¥è¯¢ç»“æœ
            for i, result in enumerate(results, 1):
                if result.success:
                    logger.info(f"âœ… [{i}] {result.display_name}")
                    logger.info(f"    æŸ¥è¯¢: {result.query}")
                    logger.info(f"    æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f}s")
                logger.info(f"    æŒ‡æ ‡æ•°: {result.metric_count}")

                # èŒƒå›´æŸ¥è¯¢ç‰¹æœ‰çš„æ•°æ®ç‚¹ä¿¡æ¯
                # è®¡ç®—å¹³å‡å€¼
                if result.is_range_query:
                    if result.metrics:
                        for j, metric in enumerate(result.metrics[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ªæŒ‡æ ‡
                            if metric.values:
                                values = [float(v['value']) for v in metric.values]
                                avg_value = sum(values) / len(values)
                                logger.info(f"    æŒ‡æ ‡ç±»å‹: {result.query_type}")
                                logger.info(f"    æŒ‡æ ‡ {j+1}: {len(metric.values)} ä¸ªæ•°æ®ç‚¹")
                                logger.info(f"      å¹³å‡å€¼: {avg_value:.2f}")
                # å¦‚æœæ˜¯å³æ—¶æŸ¥è¯¢ï¼Œæ˜¾ç¤ºæœ€æ–°å€¼
                elif result.is_instant_query:
                    if result.metrics:
                        latest_metric = result.metrics[-1]
                        logger.info(f"    æŒ‡æ ‡ç±»å‹: {result.query_type}")
                        logger.info(f"    æœ€æ–°å€¼: {latest_metric.value}")

            logger.info("")

        except Exception as e:
            logger.error(f"èŒƒå›´æŸ¥è¯¢ç¤ºä¾‹å¤±è´¥: {e}", exc_info=True)
        finally:
            await self.client.close()


    async def performance_comparison(self):
        """æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹"""
        logger.info("\n" + "=" * 60)
        logger.info("âš¡ æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹")
        logger.info("=" * 60)

        try:
            # æ„å»º 10000 ä¸ªæµ‹è¯•æŸ¥è¯¢
            test_queries = ["up", "prometheus_build_info", "process_cpu_seconds_total", "prometheus_tsdb_head_series"]
            test_queries *= 2500

            # æ–¹æ³•1: é¡ºåºæŸ¥è¯¢
            logger.info(f"æ–¹æ³•1: é¡ºåºæŸ¥è¯¢ {len(test_queries)} ä¸ªæŸ¥è¯¢")
            start_time = time.time()
            sequential_results = []
            for query in test_queries:
                result = await self.client.query(query)
                sequential_results.append(result)
            sequential_time = time.time() - start_time

            # æ–¹æ³•2: å¹¶å‘æŸ¥è¯¢
            logger.info(f"æ–¹æ³•2: å¹¶å‘æŸ¥è¯¢ {len(test_queries)} ä¸ªæŸ¥è¯¢")
            start_time = time.time()
            concurrent_results = await self.client.query_multiple(test_queries)
            concurrent_time = time.time() - start_time

            # æ€§èƒ½å¯¹æ¯”
            logger.info(f"\nğŸ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
            logger.info(f"é¡ºåºæŸ¥è¯¢è€—æ—¶: {sequential_time:.3f}s")
            logger.info(f"å¹¶å‘æŸ¥è¯¢è€—æ—¶: {concurrent_time:.3f}s")
            if concurrent_time > 0:
                speedup = sequential_time / concurrent_time
                logger.info(f"æ€§èƒ½æå‡å€æ•°: {speedup:.1f}x")

            # æˆåŠŸç‡å¯¹æ¯”
            sequential_success = sum(1 for r in sequential_results if r.success)
            concurrent_success = sum(1 for r in concurrent_results if r.success)

            logger.info(f"\nğŸ“Š æˆåŠŸç‡å¯¹æ¯”:")
            logger.info(f"é¡ºåºæŸ¥è¯¢: {sequential_success}/{len(sequential_results)} ({sequential_success/len(sequential_results)*100:.1f}%)")
            logger.info(f"å¹¶å‘æŸ¥è¯¢: {concurrent_success}/{len(concurrent_results)} ({concurrent_success/len(concurrent_results)*100:.1f}%)")

        except Exception as e:
            logger.error(f"æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹å¤±è´¥: {e}", exc_info=True)
        finally:
            await self.client.close()


async def main():
    """ä¸»å‡½æ•°"""
    try:
        demo = QueryDemo()
        # å¹¶å‘æŸ¥è¯¢ç¤ºä¾‹
        await demo.concurrent_queries_example()

        # èŒƒå›´æŸ¥è¯¢ç¤ºä¾‹
        await demo.range_queries_example()

        # æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹
        await demo.performance_comparison()

        logger.info("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆ!")

    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}",exc_info=True)
        logger.error("   è¯·ç¡®ä¿ Prometheus æ­£åœ¨è¿è¡Œåœ¨ http://localhost:9090")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}",exc_info=True)